{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111b574e-e43c-4ed7-9892-bea1fe8db7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to La_Liga_overall_stats.csv\n",
      "Data scraped and saved to La_Liga_overall_stats_squad.csv\n",
      "Merged data saved to merged_La_Liga_stats.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_table(url, table_id):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the web page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Parse the page content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the table by its ID\n",
    "    table = soup.find('table', id=table_id)\n",
    "    if table is None:\n",
    "        print(f\"Couldn't find the table with id {table_id}.\")\n",
    "        return None\n",
    "\n",
    "    # Initialize lists to hold the headers and the rows\n",
    "    headers = [header.text for header in table.find_all('th', scope='col')]\n",
    "    rows = []\n",
    "\n",
    "    # Extract the rows from the table body\n",
    "    for row in table.find('tbody').find_all('tr'):\n",
    "        # Row might start with a 'th' element for row header\n",
    "        row_header = row.find('th', scope='row')\n",
    "        row_header_text = row_header.text.strip() if row_header else None\n",
    "        cells = row.find_all('td')\n",
    "        row_data = [row_header_text] if row_header_text else []\n",
    "        row_data.extend([cell.text.strip() for cell in cells])\n",
    "        \n",
    "        if len(row_data) == len(headers):\n",
    "            rows.append(row_data)\n",
    "        else:\n",
    "            print(f\"Skipping row with mismatched columns: expected {len(headers)}, found {len(row_data)}\")\n",
    "\n",
    "    # Create a DataFrame using the headers and rows\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    return df\n",
    "\n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/12/La-Liga-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = 'results2023-2024121_overall'  # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'La_Liga_overall_stats.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/12/La-Liga-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = \"stats_squads_standard_for\"   # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'La_Liga_overall_stats_squad.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('La_Liga_overall_stats.csv')\n",
    "df2 = pd.read_csv('La_Liga_overall_stats_squad.csv')\n",
    "\n",
    "# Merge the dataframes on the team name column\n",
    "# Assuming the team name column is named 'Team' in both CSV files\n",
    "merged_df_laliga = pd.merge(df1, df2, on='Squad')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'merged_La_Liga_stats.csv'\n",
    "merged_df_laliga.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05945979-a185-4adb-b3d5-90ac0c122308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to premier_league_overall_stats.csv\n",
      "Data scraped and saved to premier_league_overall_stats_squad.csv\n",
      "Merged data saved to merged_premier_league_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Premier League\n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/9/Premier-League-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = 'results2023-202491_overall'  # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'premier_league_overall_stats.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "  \n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/9/Premier-League-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = \"stats_squads_standard_for\"   # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'premier_league_overall_stats_squad.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('premier_league_overall_stats.csv')\n",
    "df2 = pd.read_csv('premier_league_overall_stats_squad.csv')\n",
    "\n",
    "# Merge the dataframes on the team name column\n",
    "# Assuming the team name column is named 'Team' in both CSV files\n",
    "merged_df_premier = pd.merge(df1, df2, on='Squad')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'merged_premier_league_stats.csv'\n",
    "merged_df_premier.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38212f72-1f4d-4dc0-89a8-c83b9bd4c256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to SerieA_overall_stats.csv\n",
      "Data scraped and saved to SerieA_overall_stats_squad.csv\n",
      "Merged data saved to merged_SerieA_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Seria A\n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/11/Serie-A-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = 'results2023-2024111_overall'  # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'SerieA_overall_stats.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "  \n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/11/Serie-A-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = \"stats_squads_standard_for\"   # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'SerieA_overall_stats_squad.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('SerieA_overall_stats.csv')\n",
    "df2 = pd.read_csv('SerieA_overall_stats_squad.csv')\n",
    "\n",
    "# Merge the dataframes on the team name column\n",
    "# Assuming the team name column is named 'Team' in both CSV files\n",
    "merged_df_SerieA = pd.merge(df1, df2, on='Squad')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'merged_SerieA_stats.csv'\n",
    "merged_df_SerieA.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29dcb625-ac72-4eac-a90b-6841fd897ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to Bundesliga_overall_stats.csv\n",
      "Data scraped and saved to Bundesliga_overall_stats_squad.csv\n",
      "Merged data saved to merged_Bundesliga_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Bundesliga\n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/20/Bundesliga-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = 'results2023-2024201_overall'  # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Bundesliga_overall_stats.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "  \n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/20/Bundesliga-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = \"stats_squads_standard_for\"   # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Bundesliga_overall_stats_squad.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('Bundesliga_overall_stats.csv')\n",
    "df2 = pd.read_csv('Bundesliga_overall_stats_squad.csv')\n",
    "\n",
    "# Merge the dataframes on the team name column\n",
    "# Assuming the team name column is named 'Team' in both CSV files\n",
    "merged_df_Bundesliga = pd.merge(df1, df2, on='Squad')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'merged_Bundesliga_stats.csv'\n",
    "merged_df_Bundesliga.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8edcf1f-212f-4f77-8d87-8f0b89ea907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to Ligue1_overall_stats.csv\n",
      "Data scraped and saved to Ligue1_overall_stats_squad.csv\n",
      "Merged data saved to merged_Ligue1_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Ligue1\n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/13/Ligue-1-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = 'results2023-2024131_overall'  # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Ligue1_overall_stats.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "  \n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/13/Ligue-1-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = \"stats_squads_standard_for\"   # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Ligue1_overall_stats_squad.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('Ligue1_overall_stats.csv')\n",
    "df2 = pd.read_csv('Ligue1_overall_stats_squad.csv')\n",
    "\n",
    "# Merge the dataframes on the team name column\n",
    "# Assuming the team name column is named 'Team' in both CSV files\n",
    "merged_df_Ligue1 = pd.merge(df1, df2, on='Squad')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'merged_Ligue1_stats.csv'\n",
    "merged_df_Ligue1.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce02e39-3482-4272-aed2-39e3b78bb573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to Eredivisie_overall_stats.csv\n",
      "Data scraped and saved to Eredivisie_overall_stats_squad.csv\n",
      "Merged data saved to merged_Eredivisie_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Eredivisie\n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/23/Eredivisie-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = 'results2023-2024231_overall'  # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Eredivisie_overall_stats.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "  \n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/23/Eredivisie-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = \"stats_squads_standard_for\"   # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Eredivisie_overall_stats_squad.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('Eredivisie_overall_stats.csv')\n",
    "df2 = pd.read_csv('Eredivisie_overall_stats_squad.csv')\n",
    "\n",
    "# Merge the dataframes on the team name column\n",
    "# Assuming the team name column is named 'Team' in both CSV files\n",
    "merged_df_Eredivisie = pd.merge(df1, df2, on='Squad')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'merged_Eredivisie_stats.csv'\n",
    "merged_df_Eredivisie.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51055473-c6b2-41ca-a12f-bd4e1383d0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to Primeira_overall_stats.csv\n",
      "Data scraped and saved to Primeira_overall_stats_squad.csv\n",
      "Merged data saved to merged_Primeira_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Primeira\n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/32/Primeira-Liga-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = 'results2023-2024321_overall'  # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Primeira_overall_stats.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "  \n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/32/Primeira-Liga-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = \"stats_squads_standard_for\"   # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Primeira_overall_stats_squad.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('Primeira_overall_stats.csv')\n",
    "df2 = pd.read_csv('Primeira_overall_stats_squad.csv')\n",
    "\n",
    "# Merge the dataframes on the team name column\n",
    "# Assuming the team name column is named 'Team' in both CSV files\n",
    "merged_df_Primeira = pd.merge(df1, df2, on='Squad')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'merged_Primeira_stats.csv'\n",
    "merged_df_Primeira.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "303b93ea-5d1c-4bb2-9b45-5d6b5a69ae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to Belgian_overall_stats.csv\n",
      "Data scraped and saved to Belgian_overall_stats_squad.csv\n",
      "Merged data saved to merged_Belgian_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Belgian Pro League\n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/37/Belgian-Pro-League-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = 'results2023-2024370_overall'  # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Belgian_overall_stats.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "  \n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/37/Belgian-Pro-League-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = \"stats_squads_standard_for\"   # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Belgian_overall_stats_squad.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('Belgian_overall_stats.csv')\n",
    "df2 = pd.read_csv('Belgian_overall_stats_squad.csv')\n",
    "\n",
    "# Merge the dataframes on the team name column\n",
    "# Assuming the team name column is named 'Team' in both CSV files\n",
    "merged_df_Belgian = pd.merge(df1, df2, on='Squad')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'merged_Belgian_stats.csv'\n",
    "merged_df_Belgian.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d0b323-f65a-4eec-a796-f3b492cb3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row with mismatched columns: expected 13, found 12\n",
      "Data scraped and saved to Scottish_overall_stats.csv\n",
      "Data scraped and saved to Scottish_overall_stats_squad.csv\n",
      "Merged data saved to merged_Scottish_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Scottish premier league\n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/40/Scottish-Premiership-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = 'results2023-2024401_overall'  # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Scottish_overall_stats.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "  \n",
    "# URL to scrape\n",
    "url = 'https://fbref.com/en/comps/40/Scottish-Premiership-Stats'\n",
    "\n",
    "# Table ID\n",
    "table_id = \"stats_squads_standard_for\"   # Make sure this ID is correct\n",
    "\n",
    "# Scrape the table\n",
    "df = scrape_table(url, table_id)\n",
    "\n",
    "# Check if the DataFrame is not empty\n",
    "if df is not None and not df.empty:\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = 'Scottish_overall_stats_squad.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data scraped and saved to {file_path}\")\n",
    "else:\n",
    "    print(\"Data could not be scraped.\")\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('Scottish_overall_stats.csv')\n",
    "df2 = pd.read_csv('Scottish_overall_stats_squad.csv')\n",
    "\n",
    "# Merge the dataframes on the team name column\n",
    "# Assuming the team name column is named 'Team' in both CSV files\n",
    "merged_df_Scottish = pd.merge(df1, df2, on='Squad')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'merged_Scottish_stats.csv'\n",
    "merged_df_Scottish.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a53fe34-e256-4812-b720-a86e9084abf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combined_football_league_stats.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the DataFrames\n",
    "combined_df = pd.concat([merged_df_laliga, merged_df_premier, merged_df_SerieA , merged_df_Bundesliga, merged_df_Ligue1, merged_df_Eredivisie, merged_df_Primeira, merged_df_Belgian,merged_df_Scottish ], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_file_path = 'combined_football_league_stats.csv'\n",
    "combined_df.to_csv(combined_file_path, index=False)\n",
    "\n",
    "combined_file_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
